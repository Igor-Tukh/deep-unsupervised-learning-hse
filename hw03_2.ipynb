{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw03_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4dc712888d324dc99a5e2d3383524d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3aef7d17a3fd4b67ab3e49030392a54f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee6fb88a292e4e8d803a40b6c7fdaba7",
              "IPY_MODEL_83c403e217d84e75a10b1c1a9203bb4b"
            ]
          }
        },
        "3aef7d17a3fd4b67ab3e49030392a54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee6fb88a292e4e8d803a40b6c7fdaba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7d5b8fa4d2934195871d0a2879652f94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9dffed21ab8b439eac967830f477d9f8"
          }
        },
        "83c403e217d84e75a10b1c1a9203bb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97d549ac6867411a9f8d47e7f89977e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  5% 1/20 [01:02&lt;19:44, 62.32s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c1a0263a9454958b5a0f7d83f40bd36"
          }
        },
        "7d5b8fa4d2934195871d0a2879652f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9dffed21ab8b439eac967830f477d9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97d549ac6867411a9f8d47e7f89977e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c1a0263a9454958b5a0f7d83f40bd36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Igor-Tukh/deep-unsupervised-learning-hse/blob/hw03/hw03_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLEQuLYrguGr",
        "colab_type": "text"
      },
      "source": [
        "## **Deep Unsupervised Learning course, HSE, fall-winter 2019**\n",
        "## **HW 03.2**\n",
        "#### **Student: Igor Tukh**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNTv9h6bgkez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKzhxZlhgn5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrYykkyUgspD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "606093ce-2d1c-4245-b000-c25de56474ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJA7oIVshY3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESOURCES_PATH = 'gdrive/My Drive/Colab Notebooks/resources'\n",
        "PKL_PATH = os.path.join(RESOURCES_PATH, 'hw3-q2.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeSbHJsfDDoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g_tDEsPDEzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a03b895c-1b78-4dc9-f737-6404511b7679"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9eT3mLRhhpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9713c52c-7224-41e6-dfc9-134a83fe721f"
      },
      "source": [
        "with open(PKL_PATH, 'rb') as file:\n",
        "  data = pickle.load(file)\n",
        "\n",
        "print(f'Data keys: {data.keys()}')\n",
        "\n",
        "train = data['train']\n",
        "test = data['test']\n",
        "valid = data['valid']\n",
        "\n",
        "print(f'Train shape: {train.shape}, valid shape: {valid.shape}, test shape: {test.shape}')\n",
        "\n",
        "data_train = torch.from_numpy(train)\n",
        "data_test = torch.from_numpy(test)\n",
        "data_valid = torch.from_numpy(valid)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data keys: dict_keys(['train', 'valid', 'test'])\n",
            "Train shape: (65931, 32, 32, 3), valid shape: (7326, 32, 32, 3), test shape: (26032, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsXN0T8Tiz9s",
        "colab_type": "text"
      },
      "source": [
        "**a)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr7rhUqvi9qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GatedShortcutConnection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GatedShortcutConnection, self).__init__()\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.conv1 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1, 1))\n",
        "    self.conv2 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1, 1))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.conv1(x) * self.sigmoid(self.conv2(x))\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResidualStack, self).__init__()\n",
        "    layers = [nn.ReLU(), \n",
        "              nn.Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "              nn.ReLU(),\n",
        "              nn.Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "              GatedShortcutConnection()]\n",
        "\n",
        "    all_layers = nn.ModuleList()\n",
        "    for _ in range(5):\n",
        "      all_layers.extend(layers)\n",
        "    all_layers.append(nn.ReLU())\n",
        "\n",
        "    self.layers = nn.Sequential(*all_layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(nn.Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                                ResidualStack())\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "                                ResidualStack(),\n",
        "                                nn.ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)),\n",
        "                                nn.ReLU(),\n",
        "                                nn.ConvTranspose2d(128, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VAE, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "\n",
        "  def encode(self, x):\n",
        "    x = self.encoder(x)\n",
        "    mu, sigma = torch.chunk(x, 2, dim=1)\n",
        "    return mu, sigma\n",
        "\n",
        "  def decode(self, x):\n",
        "    x = self.decoder(x)\n",
        "    mu, sigma = torch.chunk(x, 2, dim=1)\n",
        "    return mu, sigma\n",
        "\n",
        "  def sample(self, mu, sigma):\n",
        "    return mu.to(device) + torch.randn(size=mu.shape).to(device) * torch.sqrt(sigma).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu, sigma = self.encode(x)\n",
        "    z = self.sample(mu, sigma)\n",
        "    mu_x, sigma_x = self.decode(z)\n",
        "    return mu, sigma, mu_x, sigma_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQbzrsHZ5O_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nn.MSELoss()\n",
        "\n",
        "def get_loss(x, output):\n",
        "  mu, sigma, mu_x, sigma_x = output\n",
        "  pl = -0.5 * (torch.log(np.pi * 2 * sigma_x) + torch.pow(x - mu_x, 2) / sigma_x)\n",
        "  # pl = -pl.sum(dim=1)\n",
        "  pl = pl.mean()\n",
        "  # pl = loss(output, x)\n",
        "  kl = -0.5 * (1. + torch.log(sigma) - mu**2 - sigma)\n",
        "  kl = kl.sum(dim=1)\n",
        "  kl = kl.mean()\n",
        "  return pl, kl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAU9I55M5PRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_losses(train_losses, val_losses, title='Losses'):\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  epoches = range(0, len(train_losses))\n",
        "  plt.plot(epoches, train_losses, label='train loss')\n",
        "  plt.plot(epoches, val_losses, label='val loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWyMbAiR5RA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_batches, val_batches, lossf=get_loss, epoches_number=20, lr=1e-2, batch_size=100, epoch_print=1):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  for epoch in tqdm(range(epoches_number)):\n",
        "    losses = []\n",
        "    for batch in train_batches:\n",
        "      batch = batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(batch)\n",
        "      pl, kl = lossf(batch, output)\n",
        "      # print(pl, kl)\n",
        "      loss = pl + kl\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      losses.append([pl.detach().cpu().numpy(), kl.detach().cpu().numpy()])\n",
        "    losses = np.array(losses)\n",
        "    train_losses.append([losses[:,0].mean(), losses[:,1].mean()])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      losses = []\n",
        "      for batch in val_batches:\n",
        "        batch = batch.to(device)\n",
        "        output = model(batch)\n",
        "        pl, kl = lossf(batch, output)\n",
        "        loss = pl + kl\n",
        "        losses.append((pl.detach().cpu().numpy(), kl.detach().cpu().numpy()))\n",
        "    losses = np.array(losses)\n",
        "    val_losses.append([losses[:,0].mean(), losses[:,1].mean()])\n",
        "    \n",
        "    if epoch % epoch_print == 0 or epoch == epoches_number - 1:\n",
        "      train_loss = np.mean(train_losses[-1])\n",
        "      val_loss = np.mean(val_losses[-1])\n",
        "      print(f'Epoch: {epoch}, train loss: {train_loss}, val loss: {val_loss}')\n",
        "    \n",
        "  train_losses = np.array(train_losses)\n",
        "  val_losses = np.array(val_losses)\n",
        "\n",
        "  plot_losses(train_losses[:,0], val_losses[:, 0], title='Prob losses')\n",
        "  plot_losses(train_losses[:,1], val_losses[:, 1], title='KL losses')\n",
        "  plot_losses(train_losses.sum(axis=1), val_losses.sum(axis=1), title='Losses')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0WZ7Dx-5UAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 200\n",
        "\n",
        "dt = 1. * data_train.permute(0, 3, 1, 2) / 255\n",
        "dv = 1. * data_valid.permute(0, 3, 1, 2) / 255\n",
        "\n",
        "train_batches = torch.utils.data.DataLoader(dt, batch_size=batch_size)\n",
        "validate_batches = torch.utils.data.DataLoader(dv, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89K8sIWFAM3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "4dc712888d324dc99a5e2d3383524d81",
            "3aef7d17a3fd4b67ab3e49030392a54f",
            "ee6fb88a292e4e8d803a40b6c7fdaba7",
            "83c403e217d84e75a10b1c1a9203bb4b",
            "7d5b8fa4d2934195871d0a2879652f94",
            "9dffed21ab8b439eac967830f477d9f8",
            "97d549ac6867411a9f8d47e7f89977e4",
            "1c1a0263a9454958b5a0f7d83f40bd36"
          ]
        },
        "outputId": "844b4aed-c48d-4fbd-b1e1-f87240c4a68b"
      },
      "source": [
        "model = VAE().to(device)\n",
        "train(model, train_batches, validate_batches)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dc712888d324dc99a5e2d3383524d81",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, train loss: nan, val loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-210df1ebe2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-201dad8cd97c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_batches, val_batches, lossf, epoches_number, lr, batch_size, epoch_print)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}